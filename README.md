# Personio : organization-board
REST API FOR ORGANIZATION TEAM STRUCTURE/HIERARCHY MANAGMENT

## Getting Started

### Requirements :
```
* GO 1.14
```
Install GO from [here](https://golang.org/dl/) <br/>
All other required dependancies are already part of the project.

### Run Test Cases
```
./tests.sh
```
### Run The project
Script builds GO binary and runs the binary.
```
./run.sh
```
## CURL Requests For Testing The APP
* Login and Get JWT token
```
curl -v -d '{"email": "personia@personio.com", "password": "personia"}' -H 'Content-Type: application/json' http://localhost:9090/api/v1/login | json_pp
```
* POST valid Employee to Manager Mapping
```
curl -d '{"Pete": "Nick","Barbara": "Nick","Nick": "Sophie"}' -H 'Content-Type: application/json' -H 'Authorization: BEARER <strong><em>TOKEN_From_First_Curl</strong></em>' http://localhost:9090/api/v1/emplymgrmap | json_pp
```
* POST Employee to Manager Mapping having loop
```
curl -d '{"Pete": "Nick","Barbara": "Nick","Nick": "Sophie","Sophie": "Pete"}' -H 'Content-Type: application/json' -H 'Authorization: BEARER <strong><em>TOKEN_From_First_Curl</strong></em>' http://localhost:9090/api/v1/emplymgrmap? | json_pp
```
* POST Employee to Manager Mapping having Multiple Root Employees
```
curl -d '{"Pete": "Nick","Barbara": "Nick","Nick": "Sophie", "John": "Peter"}' -H 'Content-Type: application/json' -H 'Authorization: BEARER <strong><em>TOKEN_From_First_Curl</strong></em>' http://localhost:9090/api/v1/emplymgrmap | json_pp
```
* GET complete Employee to Manager mapping
```
curl -H 'Content-Type: application/json' -H 'Authorization: BEARER <strong><em>TOKEN_From_First_Curl</strong></em>' http://localhost:9090/api/v1/emplymgrmap? | json_pp
```
* GET Supervisor Info of an Employee
```
curl -H 'Content-Type: application/json' -H 'Authorization: BEARER <strong><em>TOKEN_From_First_Curl</strong></em>' http://localhost:9090/api/v1/emplymgrmap/Nick?supervisor=true
```

## Application Design

### High Level Design :
The project is divided into two main module.<br/>
1. Query Parser : Tokenizes and parses CSV query into internal representation.
2. Query Executor : Consumes Query generated by parser and returns result of the query execution

#### Query Parser :
* Query parser is implemented as state machine as depicted in the picture below.
* The parser FSM(finite state machine) has "FROM/JOIN/COUNTBY/ORDERBY/TAKE/SELECT" as valid states.
* It starts with the parsing of `FROM` state and prceeeds through the other states.
* Each state except `FROM` is optional and if present parser makes sure the input fields required at each state are parsed as well. <br/>Eg: Two CSV files and a column for `JOIN` state
* The ordering of the states is ensured by default. So one can not enter `SELECT` after `TAKE`.<br/> `"FROM abc.CSV SELECT column1 TAKE 10"` is invalid.
* Parse also makes sure input validations are performed such as:<br/>
<pre>
  1. Query is not empty and does not contain any gibbereish or non-parseable tokens.
  2. FROM    : At least one CSV file is specified.
  3. JOIN    : Two CSV files with a join-key are specified.
  4. COUNTBY : Column is specified for aggregation.
  5. ORDERBY : column is specified for sorting in descending order.
  6. TAKE    : Valid integer value is specifie to limit the output size.
  7. SELECT  : Column/columns are specified for filtering.
</pre>

![alt text](Query-FSM.jpg "Query FSM")

#### Query Executor :
* Query executor is designed as the pipeline of higher order functions to lower functions on input data and the internal Query represntation generated by the Query Parser.
* It reads colums keys and data rows from first file and then executes `JOIN->COUNTBY->ORDERBY->TAKE->SELECT` functions sequnetially of course depending on what is being asked in the query :).
* Execution result of each function is cached and then fed into next function with final output returned as the query result.
* It supports two variations for performing join - a simple join and a Sort Merge Join.
* Executor also handles any errors encountered during query execution and returns them to the client such as
<pre>
  1. All CSV files specified in the query, do exist, are not empty and there are valid permissions to access them.
  2. JOIN    : Join coulmn is present in CSV files.
  3. COUNTBY : Countby column is present.
  4. ORDERBY : Orderby column is present and entire column data is in integer format.
  5. TAKE    : Negative values, zero value or values more than data size are handled.
  6. SELECT  : Select Column/columns are present.
</pre>
#### File Operations :
A wrapper over GO's CSV file operation APIs.
#### Custom Errors :
A detailed list of errors covering query input, parsing and execution phase.
#### Util :
Provies print functionality for errors and query output.
Query output is printed in either `CSV` or `Tabular` format.
#### Testing :
Each module mentioned above, has extensive test coverage and each code file is accompnied by the corresponding test file.


## Assumptions
1.  For task No 2, We only support POST semantics for hierarchies. So on each new POST request, we do overwrite the hierarchies in sqlite.
2. Response for the task No 3, response for retrieving supervisor and super-supervisor is :
```
{
  "supervisor" : "Nick",
  "supervisor_of_supervisor" : "Sophie"
}
```

## Improvement Ideas
* BDD frameworks [Gingko](https://onsi.github.io/ginkgo/), [Gomega](https://onsi.github.io/gomega/) can be used for more expressive test cases.
* Scale/Perf run the app with [pprof](https://blog.golang.org/pprof) to find out any cpu, memory, performance bottlenecks.
* Improve metric, tracing and logging of app. Use [zap](https://github.com/uber-go/zap)
* All the errors can be numbered to build full fledged documentation around it.
* Have a postman collection for all the supported API calls.